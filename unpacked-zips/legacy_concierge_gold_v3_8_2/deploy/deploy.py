
# deploy_v3_5.py â€” v (Audit Fix Patch)
# Entry points preserved: # Implements:
# - True relations (from "Related Page Title")
# - Acceptance DB "Check" as Notion formula
# - Rich-text seeds (italic/gray) for Notes
# - Multi-select defaults
# - Synced blocks library + copies
# - Grid dashboards, hero blocks, nav links
# - Robust req() with retries incl. 504; JSON helpers
# - All helper functions defined; idempotent markers
import os, sys, json, time, argparse
import requests
import urllib.parse
import math
import yaml

# Import constants and modules
from constants import *
from csv_importer import import_csv_data
from permissions import setup_role_permissions
from mobile_optimizer import optimize_for_mobile
from synced_rollups import setup_synced_rollups
from template_versioning import setup_template_versioning
from data_validation import setup_data_validation
from relation_integrity import setup_relation_integrity
from batch_operations import setup_batch_operations
from formula_sync import setup_formula_sync
from conditional_pages import setup_conditional_pages
from progress_dashboard import setup_progress_dashboard
from friends_contact_page import setup_friends_contact_page

ENABLE_SEARCH_FALLBACK = os.getenv("ENABLE_SEARCH_FALLBACK","1") in ("1","true","True","yes","YES")

def expect_ok(resp, context=""):
    if resp is None:
        print("ERROR:", context, "no response"); return False
    if resp.status_code not in (200,201):
        try:
            body = resp.json()
        except Exception:
            body = resp.text
        print("ERROR:", context, resp.status_code, body)
        return False
    return True

def find_page_id_by_title(title, state):
    pid = state["pages"].get(title)
    if pid:
        return pid
    if not ENABLE_SEARCH_FALLBACK:
        return None
    payload = {
        "query": title,
        "filter": {"value":"page","property":"object"}
    }
    r = req("POST",ENDPOINT_SEARCH, data=json.dumps(payload))
    if r.status_code in (200,201):
        data = j(r)
        for res in data.get("results",[]):
            # Try to read the page title property (varies by DB/page)
            props = res.get("properties",{})
            name = None
            for p in props.values():
                if p.get("type")=="title":
                    name = "".join([t.get("plain_text","") for t in p.get("title",[])])
                    break
            if not name and res.get("object")=="page":
                # fallback to plain title in properties.title
                pass
            if name and name.strip()==title.strip():
                return res.get("id")
    return None

# Single url_join implementation (refactored from 3 duplicates)
def url_join(base, filename):
    """Join base URL with filename, handling slashes and URL encoding."""
    filename = filename.lstrip("/")
    return base.rstrip("/") + "/" + urllib.parse.quote(filename)


NOTION_TOKEN = os.getenv(ENV_NOTION_TOKEN)
NOTION_VERSION = os.getenv(ENV_NOTION_VERSION, NOTION_API_VERSION)

GLOBAL_THROTTLE_RPS = float(os.getenv("THROTTLE_RPS","2.5"))
_LAST_REQ_TS = [0.0]

def _throttle():
    import time
    if GLOBAL_THROTTLE_RPS <= 0:
        return
    min_interval = 1.0 / GLOBAL_THROTTLE_RPS
    now = time.time()
    elapsed = now - _LAST_REQ_TS[0]
    if elapsed < min_interval:
        time.sleep(min_interval - elapsed + 0.02)
    _LAST_REQ_TS[0] = time.time()

def req(method, url, headers=None, data=None, files=None, timeout=None):
    headers = headers or {}
    if "Notion-Version" not in headers:
        headers["Notion-Version"] = os.getenv(ENV_NOTION_VERSION, NOTION_API_VERSION)
    if "Authorization" not in headers:
        headers["Authorization"] = f'Bearer {os.getenv("NOTION_TOKEN","")}'
    if "Content-Type" not in headers and data is not None and files is None:
        headers["Content-Type"] = "application/json"
    timeout = timeout or int(os.getenv("NOTION_TIMEOUT","25"))
    max_try = int(os.getenv("RETRY_MAX","5"))
    backoff = float(os.getenv("RETRY_BACKOFF_BASE","1.5"))
    for attempt in range(max_try):
        try:
            r = _throttle(); requests.request(method, url, headers=headers, data=data, files=files, timeout=timeout)
        except requests.exceptions.Timeout:
            if attempt == max_try-1: raise
            time.sleep(backoff * (attempt+1)); continue
        except requests.exceptions.RequestException as e:
            # network failure
            if attempt == max_try-1: raise
            time.sleep(backoff * (attempt+1)); continue
        if r.status_code in (429, 500, 502, 503, 504):
            # retryable
            time.sleep(backoff * (attempt+1)); continue
        # return on any non-retryable
        return r
    return r
    return r

def j(resp):
    try:
        return resp.json()
    except Exception:
        return {}

def resolve_icon(spec):
    if not spec: return None
    if spec.startswith("emoji:"):
        return {"type":"emoji","emoji": spec.split(":",1)[1]}
    base = os.getenv("ASSET_BASE_URL") or os.getenv("ICON_BASE_URL")
    if base and (spec.endswith(".png") or spec.endswith(".jpg") or spec.endswith(".jpeg") or spec.endswith(".svg")):
        return {"type":"external","external":{"url": url_join(base, spec)}}
    return {"type":"emoji","emoji":"ðŸ“„"}

def helper_toggle(summary, bullets):
    return {"object":"block","type":"toggle","toggle":{"rich_text":[{"type":"text","text":{"content":summary}}],
            "children":[{"object":"block","type":"bulleted_list_item","bulleted_list_item":{"rich_text":[{"type":"text","text":{"content":b}}]}} for b in bullets]}}

def rt(text, italic=False, bold=False, color="gray"):
    return [{"type":"text","text":{"content":str(text)},"annotations":{"italic":italic,"bold":bold,"color":color}}]

def has_marker(pid, text_snippet):
    r = req("GET", f"{ENDPOINT_BLOCKS}/{pid}/children")
    data = j(r)
    for b in data.get("results", []):
        t = b.get("type")
        if t in ["paragraph","heading_1","heading_2","heading_3","callout","bulleted_list_item","numbered_list_item","to_do","toggle"]:
            rtxt = b[t].get("rich_text",[])
            txt = "".join([x.get("plain_text","") for x in rtxt])
            if text_snippet.lower() in txt.lower():
                return True
    return False

def create_page(parent_id, title, icon=None, cover=None, description=None, helpers=None, role=None):
    payload = {"parent":{"type":"page_id","page_id":parent_id},
               "icon": icon, "cover": cover,
               "properties":{"title":{"title":[{"type":"text","text":{"content":title}}]}}}
    r = req("POST",ENDPOINT_PAGES, data=json.dumps(payload))
    if r.status_code not in (200,201):
        print("ERROR creating page", title, r.text); return None
    pid = j(r)["id"]
    # Build hero + description + helpers in one pass to avoid duplicates later
    blocks = []
    blocks += make_hero_blocks(title, role)
    if description:
        blocks.append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt(description)}})
    if helpers:
        for helper in helpers:
            blocks.append(helper_toggle(str(helper), ["Please complete this step."]))
    if blocks:
        req("PATCH", f"{ENDPOINT_BLOCKS}/{pid}/children", data=json.dumps({"children":blocks}))
    return pid

def role_color(role):
    r = (role or "owner").lower()
    return "blue_background" if r=="executor" else ("orange_background" if r=="family" else "gray_background")

def make_hero_blocks(title, role):
    return [
        {"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"â¬¢"},"rich_text": rt("HERO_MARKER  This page helps you with: " + title, bold=True),"color": role_color(role)}},
        {"object":"block","type":"divider","divider":{}}
    ]

def grid_cards(items, cols=3):
    n=len(items)
    if n==0: return []
    cols=max(1, min(3, n))
    columns=[[] for _ in range(cols)]
    # seed one per column
    for i in range(min(n, cols)):
        it = items[i]
        tile={"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"â¬¢"},"rich_text": rt(it.get("title","")),"color": role_color(it.get("role"))}}
        columns[i].append(tile)
        if it.get("subtitle"):
            columns[i].append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt(it["subtitle"])}})
        if it.get("page_id"):
            columns[i].append({"object":"block","type":"link_to_page","link_to_page":{"type":"page_id","page_id": it["page_id"]}})
        columns[i].append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt(" ")}})
    for i in range(cols, n):
        it = items[i]
        c = i % cols
        tile={"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"â¬¢"},"rich_text": rt(it.get("title","")),"color": role_color(it.get("role"))}}
        columns[c].append(tile)
        if it.get("subtitle"):
            columns[c].append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt(it["subtitle"])}})
        if it.get("page_id"):
            columns[c].append({"object":"block","type":"link_to_page","link_to_page":{"type":"page_id","page_id": it["page_id"]}})
        columns[c].append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt(" ")}})
    col_blocks=[{"object":"block","type":"column","column":{"children": blocks}} for blocks in columns]
    return [{"object":"block","type":"column_list","column_list":{}}, *col_blocks]

def create_database(parent_id, title, schema, state):
    warnings = validate_formula_complexity(schema, title)
    for w in warnings:
        print("â€¢", w)
props = {}
    for name, spec in (schema.get("properties") or {}).items():
        t = spec if isinstance(spec, str) else spec.get("type") or "rich_text"
        if t=="title": props[name]={"title":{}}
        elif t in ("text","rich_text"): props[name]={"rich_text":{}}
        elif t=="number": props[name]={"number":{"format":"number"}}
        elif t=="select": props[name]={"select":{"options":[{"name":o} for o in (spec.get("options") if isinstance(spec, dict) else [])]}}
        elif t=="multi_select": props[name]={"multi_select":{"options":[{"name":o} for o in (spec.get("options") if isinstance(spec, dict) else [])]}}
        elif t=="date": props[name]={"date":{}}
        elif t=="url": props[name]={"url":{}}
        elif t=="relation": props[name]={"relation":{"database_id": state.get("pages_index_db") or "", "type":"single_property", "single_property":{}}}
        elif t=="formula":
            expr = spec.get("formula") or spec.get("expression") or '""'
            props[name]={"formula":{"expression": expr}}
        else: props[name]={"rich_text":{}}
    payload = {"parent":{"type":"page_id","page_id":parent_id},"title":[{"type":"text","text":{"content":title}}],"properties":props}
    r = req("POST",ENDPOINT_DATABASES, data=json.dumps(payload))
    expect_ok(r, f"create DB {title}")
    dbid = j(r).get("id")
    # If Acceptance/Setup, ensure Check formula exists
    if dbid and (title.lower().startswith("acceptance") or title.lower().startswith("setup")):
        req("PATCH", f"{ENDPOINT_DATABASES}/{dbid}", data=json.dumps({"properties":{"Check":{"formula":{"expression":'if(prop("Status") == "Done", "âœ…", "")'}}}}))
    return dbid

def insert_db_rows(dbid, rows, state, db_name=None):
    meta = j(req("GET", f"{ENDPOINT_DATABASES}/{dbid}"))
    pmap = meta.get("properties",{})
    for row in rows or []:
        # Merge Notes -> Note to avoid conflicts
        if "Notes" in row and "Note" not in row:
            row["Note"] = row.pop("Notes")
        props={}
        # Prefetch related page title if needed
        target_title = row.get("Related Page Title") or row.get("Related Page")
        target_pid = None
        if target_title and "Related Page" in pmap:
                # Resolve to Pages Index DB item
                idx_db = state.get("pages_index_db")
                idx_item = find_index_item_by_title(idx_db, str(target_title)) if idx_db else None
                if idx_item:
                    props["Related Page"]={"relation":[{"id":idx_item}]}
                else:
                    ensure_property_rich_text(dbid, "Intended Relation")
                    props["Intended Relation"]={"rich_text": rt(f"{target_title} (not found)", italic=True, color="gray")}
                continue
            if k in ["Related Page Title","Related Page"]:
                if target_pid:
                    props["Related Page"]={"relation":[{"id":target_pid}]}
                else:
                    # keep a breadcrumb of intended title
                    if "Intended Relation" in pmap:
                        props["Intended Relation"]={"rich_text": rt(str(v), italic=True, color="gray")}
                continue
            # Title
            if k in pmap and pmap[k]["type"]=="title":
                props[k]={"title":[{"type":"text","text":{"content":str(v)}}]}; continue
            # Select
            if k in pmap and pmap[k]["type"]=="select":
                props[k]={"select":{"name": str(v)}}; continue
            # Multi-select
            if k in pmap and pmap[k]["type"]=="multi_select":
                items = v if isinstance(v,list) else [v]
                props[k]={"multi_select":[{"name":str(x)} for x in items]}; continue
            # Number
            if k in pmap and pmap[k]["type"]=="number":
                try: num=float(v)
                except: num=None
                props[k]={"number": num}; continue
            # Rich text for Note
            if k.lower() in ["note","notes"] or k.endswith(" Note"):
                props["Note" if "Note" in pmap else k]={"rich_text": rt(v, italic=True, color="gray")}; continue
            # Fallback rich_text
            if k in pmap:
                props[k]={"rich_text":[{"type":"text","text":{"content":str(v)}}]}
        created = req("POST",ENDPOINT_PAGES, data=json.dumps({"parent":{"database_id":dbid},"properties":props}))
        expect_ok(created, f"seed row in {dbid}")
    return pid

    # Create top-level hubs known by title (if defined in YAML)
    # We rely on merged["pages"] entries to create pages; hubs are inferred by matches
    if args.dry_run:
        print("DRY-RUN: would create", len(merged["pages"]), "pages and", len(merged["db"]["schemas"]), "databases")
        # Show a subset
        for p in merged["pages"][:10]:
            print(" - Page:", p.get("title"))
        for k in list(merged["db"]["schemas"].keys())[:10]:
            print(" - DB:", k)
        return

    # Pages Index DB first
    state["pages_index_db"] = ensure_pages_index_db(parent)

    # PREVIEW
    preview_plan(merged)
    resp = os.getenv("AUTO_YES")
    if not resp:
        resp = input("Proceed with deployment? (y/n): ").strip().lower()
    if resp not in ("y","yes","1","true"):
        print("Aborted by user.")
        return

    # Create all pages first (to resolve relations by title later)
    for p in merged["pages"]:

        upsert_page(p.get("title"), p.get("parent"), p.get("icon"), p.get("cover_png") or p.get("cover"), p.get("description"), p.get("helper"), p.get("role"))

    # Hero blocks already injected in create_page
    # Dashboards: simple grid on hubs if they exist
    hubs = ["Preparation Hub","Executor Hub","Family Hub"]
    hub_ids = {t: state["pages"].get(t) for t in hubs if state["pages"].get(t)}
    for hub, hid in hub_ids.items():
        # Build grid of its children by scanning merged pages with parent==hub
        children=[p.get("title") for p in merged["pages"] if p.get("parent")==hub]
        items=[]
        for t in children:
            cid=state["pages"].get(t); role="owner" if hub=="Preparation Hub" else ("executor" if hub=="Executor Hub" else "family")
            if cid: items.append({"title":t,"subtitle":None,"page_id":cid,"role":role})
        grid=grid_cards(items, cols=3)
        req("PATCH", f"{ENDPOINT_BLOCKS}/{hid}/children", data=json.dumps({"children":grid}))

    # Add mobile tips to hubs
    add_mobile_tip(state, merged["pages"])

    # Create databases
    for db_name, schema in merged["db"]["schemas"].items():
        dbid = create_database(parent, db_name, schema)
        if not dbid: continue
        state["dbs"][db_name]=dbid
        # If Acceptance DB, patch its Check as a formula
        if db_name.lower().startswith("acceptance") or db_name=="Setup & Acceptance":
            # ensure formula
            # Update property to formula via patch (Notion doesn't support partial schema patch fully; but try)
            props={"properties":{"Check":{"formula":{"expression":'if(prop("Status") == "Done", "âœ…", "")'}}}}
            req("PATCH", f"{ENDPOINT_DATABASES}/{dbid}", data=json.dumps(props))
        # Seed rows
        rows = (schema.get("seed_rows") or [])
        if rows: insert_db_rows(dbid, rows, state)

    # Synced blocks library (legal/letters/executor notes)
    def create_synced_library():
        lib_id = create_page(parent, "Admin â€“ Synced Library", {"type":"emoji","emoji":"ðŸ“Œ"}, None, "Master synced blocks for disclaimers and helpers.", None, None)
        if not lib_id: return None, {}
        children=[
            {"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"âš–ï¸"},"rich_text": rt("Legal documents: This workspace offers general guidance only. It is not legal advice."),"color":"gray_background"}},
            {"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"âœ‰ï¸"},"rich_text": rt("Letters: Confirm each recipientâ€™s requirements before sending."),"color":"gray_background"}},
            {"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"ðŸ§­"},"rich_text": rt("Executor: You donâ€™t have to do this all at once. Start with the first, easiest step."),"color":"gray_background"}},
        ]
        r = req("PATCH", f"{ENDPOINT_BLOCKS}/{lib_id}/children", data=json.dumps({"children":children}))
        data=j(r); sync_map={}
        for b in data.get("results", []):
            text="".join([t.get("plain_text","") for t in b.get("callout",{}).get("rich_text",[])])
            key=text.split(":")[0] if ":" in text else text[:16]
            sync_map[key]=b["id"]
        return lib_id, sync_map

    
def add_synced_to_pages(sync_map):
    pairs=[("LEGAL","Legal Documents"),("LETTERS","Letters"),("EXECUTOR","Executor Hub")]
    for key, page_title in pairs:
        pid=state["pages"].get(page_title)
        if not pid or key not in sync_map: continue
        src_id=sync_map[key]
        # idempotency: skip if a synced_block already references src_id
        existing = get_children(pid)
        found = False
        for b in existing:
            if b.get("type")=="synced_block":
                sf = b["synced_block"].get("synced_from")
                if sf and sf.get("block_id")==src_id:
                    found=True; break
        if found: 
            continue
        block={"object":"block","type":"synced_block","synced_block":{"synced_from":{"block_id":src_id}}}
        insert_children(pid, [block])
    return
 {"object":"block","type":"link_to_page","link_to_page":{"type":"page_id","page_id": pid}}

def add_nav_links(state, pages_cfg):
    # Build parent -> children mapping in listed order
    children_by_parent={}
    for p in pages_cfg:
        parent=p.get("parent")
        children_by_parent.setdefault(parent or "__ROOT__", []).append(p.get("title"))
    # For each page with a parent, add Back and Next links
    for p in pages_cfg:
        title=p.get("title"); parent=p.get("parent")
        if not parent: continue
        pid = state["pages"].get(title); par_id = state["pages"].get(parent)
        if not pid or not par_id: continue
        sibs = children_by_parent.get(parent, [])
        try:
            idx=sibs.index(title)
        except ValueError:
            idx=None
        next_pid=None
        if idx is not None and idx+1 < len(sibs):
            next_title=sibs[idx+1]
            next_pid = state["pages"].get(next_title)
        blocks=[]
        # Navigation group
        nav_children=[]
        nav_children.append({"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"â†©ï¸"},"rich_text": rt("Back to " + parent),"color":"gray_background"}})
        nav_children.append(link_to_page_block(par_id))
        if next_pid:
            nav_children.append({"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"âž¡ï¸"},"rich_text": rt("Next step"),"color":"gray_background"}})
            nav_children.append(link_to_page_block(next_pid))
        blocks.append({"object":"block","type":"toggle","toggle":{"rich_text": rt("Navigation"),"children": nav_children}})
        req("PATCH", f"{ENDPOINT_BLOCKS}/{pid}/children", data=json.dumps({"children":blocks}))

def add_mobile_tip(state, pages_cfg):
    # Treat hubs from YAML if marked, else fallback to known names
    hub_titles=set()
    for p in pages_cfg:
        if p.get("hub") is True:
            hub_titles.add(p.get("title"))
    if not hub_titles:
        hub_titles.update(["Preparation Hub","Executor Hub","Family Hub"])
    tip='On phones, use the â€¢â€¢â€¢ menu to jump sections. Tiles stack vertically.'
    for t in hub_titles:
        pid=state["pages"].get(t)
        if not pid: continue
        block={"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"ðŸ“±"},"rich_text": rt(tip, italic=True, color="gray"),"color":"gray_background"}}
        req("PATCH", f"{ENDPOINT_BLOCKS}/{pid}/children", data=json.dumps({"children":[block]}) )

def add_letter_legal_content(state, pages_cfg):
    # If a page dict includes Body/Disclaimer, render them
    for p in pages_cfg:
        title=p.get("title"); pid=state["pages"].get(title)
        if not pid: continue
        body = p.get("Body") or p.get("body")
        disclaimer = p.get("Disclaimer") or p.get("disclaimer")
        if not (body or disclaimer): continue
        children=[]
        if body:
            children.append({"object":"block","type":"toggle","toggle":{"rich_text": rt("Draft (expand)"),"children":[{"object":"block","type":"paragraph","paragraph":{"rich_text": rt(body)}}]}})
        if disclaimer:
            children.append({"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"âš ï¸"},"rich_text": rt(disclaimer),"color":"gray_background"}})
        if children:
            req("PATCH", f"{ENDPOINT_BLOCKS}/{pid}/children", data=json.dumps({"children":children}))

def get_children(pid, page_size=100):
    r = req("GET", f"{ENDPOINT_BLOCKS}/{pid}/children?page_size={page_size}")
    return j(r).get("results", [])

def plain_text(rtlist):
    return "".join([x.get("plain_text","") for x in (rtlist or [])])

def has_block_marker(pid, token):
    results = get_children(pid)
    for b in results:
        t = b.get("type")
        if t in ("paragraph","callout","toggle","bulleted_list_item","numbered_list_item","to_do"):
            txt = plain_text(b[t].get("rich_text",[]))
            if token in txt:
                return True
        if t=="synced_block":
            # check first child
            sc = req("GET", f"{ENDPOINT_BLOCKS}/{b['id']}/children")
            scj = j(sc)
            for cb in scj.get("results",[]):
                tt = cb.get("type")
                if tt in ("paragraph","callout","toggle"):
                    if token in plain_text(cb[tt].get("rich_text",[])):
                        return True
    return False

def insert_children(pid, blocks):
    return req("PATCH", f"{ENDPOINT_BLOCKS}/{pid}/children", data=json.dumps({"children":blocks}))




def ensure_pages_index_db(parent_id):
    title = "Admin â€“ Pages Index"
    # Create minimal DB
    schema = {"properties":{
        "Name":{"type":"title"},
        "Page ID":{"type":"rich_text"},
        "URL":{"type":"url"}
    }}
    payload = {"parent":{"type":"page_id","page_id":parent_id},
               "title":[{"type":"text","text":{"content":title}}],
               "properties":{"Name":{"title":{}},"Page ID":{"rich_text":{}},"URL":{"url":{}}}}
    r = req("POST",ENDPOINT_DATABASES, data=json.dumps(payload))
    if not expect_ok(r, "create Pages Index DB"): return None
    return j(r).get("id")

def upsert_pages_index_row(dbid, title, pid):
    # Build URL (Notion doesn't expose public URL via API; leave blank or use internal scheme if known)
    url = None
    # Query by title exact match
    q = req("POST", f"{ENDPOINT_DATABASES}/{dbid}/query", data=json.dumps({"page_size":5, "filter":{"property":"Name","title":{"equals": title}}}))
    data = j(q)
    existing = (data.get("results") or [])
    props={"Name":{"title":[{"type":"text","text":{"content":title}}]},"Page ID":{"rich_text": rt(pid)}}
    if url: props["URL"]={"url": url}
    if existing:
        page_id = existing[0]["id"]
        req("PATCH", f"{ENDPOINT_PAGES}/{page_id}", data=json.dumps({"properties":props}))
        return page_id
    else:
        cr = req("POST",ENDPOINT_PAGES, data=json.dumps({"parent":{"database_id":dbid},"properties":props}))
        if expect_ok(cr, "insert pages index row"):
            return j(cr).get("id")
    return None



def ensure_property_rich_text(dbid, name):
    meta = j(req("GET", f"{ENDPOINT_DATABASES}/{dbid}"))
    if name in meta.get("properties", {}):
        return
    req("PATCH", f"{ENDPOINT_DATABASES}/{dbid}", data=json.dumps({"properties":{name:{"rich_text":{}}}}))

def find_index_item_by_title(dbid, title):
    q = req("POST", f"{ENDPOINT_DATABASES}/{dbid}/query", data=json.dumps({"page_size":10, "filter":{"property":"Name","title":{"equals": title}}}))
    data = j(q)
    for res in data.get("results",[]):
        return res.get("id")
    return None



def query_database_all(dbid):
    has_more=True; start=None; results=[]
    while has_more:
        payload = {"page_size":100}
        if start: payload["start_cursor"]=start
        r = req("POST", f"{ENDPOINT_DATABASES}/{dbid}/query", data=json.dumps(payload))
        if not expect_ok(r, f"query DB {dbid}"): break
        data = j(r)
        results.extend(data.get("results",[]))
        has_more = data.get("has_more")
        start = data.get("next_cursor")
    return results

def update_rollout_summary(state):
    # Find Acceptance DB id
    acc = None
    for name, dbid in state.get("dbs",{}).items():
        if name.lower().startswith("acceptance") or name.lower().startswith("setup"):
            acc = dbid; break
    if not acc: 
        return
    rows = query_database_all(acc)
    # compute by 'Section' (fallback 'Role' or 'Category')
    def read_prop(page, key):
        p = page.get("properties",{}).get(key)
        if not p: return None
        t = p.get("type")
        if t=="select": return p["select"]["name"] if p.get("select") else None
        if t=="title": return plain_text(p["title"])
        if t=="rich_text": return plain_text(p["rich_text"])
        return None
    summary={}
    total=0; done=0
    for r in rows:
        section = read_prop(r, "Section") or read_prop(r, "Role") or "General"
        status = read_prop(r, "Status") or ""
        total += 1
        if section not in summary: summary[section]={"total":0,"done":0}
        summary[section]["total"] += 1
        if status.lower()=="done": 
            summary[section]["done"] += 1
            done += 1
    remaining = total - done
    # Upsert "Admin â€“ Rollout Summary" page
    title = "Admin â€“ Rollout Summary"
    pid = state["pages"].get(title)
    if not pid:
        pid = create_page(parent, title, {"type":"emoji","emoji":"ðŸ§©"}, None, "Live deployment progress summary.", None, None)
        state["pages"][title]=pid
    # Build table as paragraphs
    blocks=[
        {"object":"block","type":"paragraph","paragraph":{"rich_text": rt("ROLLUP_START")}},
        {"object":"block","type":"paragraph","paragraph":{"rich_text": rt(f"Total: {total} â€¢ Done: {done} â€¢ Remaining: {remaining}")}},
        {"object":"block","type":"divider","divider":{}},
    ]
    for sec, v in sorted(summary.items()):
        pct = 0 if v["total"]==0 else int(round(100 * v["done"]/v["total"]))
        blocks.append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt(f"{sec}: {v['done']}/{v['total']} ({pct}%)")}})
    blocks.append({"object":"block","type":"paragraph","paragraph":{"rich_text": rt("ROLLUP_END")}})
    insert_children(pid, blocks)



def preview_plan(merged):
    total_pages = len(merged.get("pages", []))
    total_dbs = len(merged.get("db", {}).get("schemas", {}))
    print("=== Deployment Preview ===")
    print(f"Pages to ensure: {total_pages}")
    print(f"Databases to ensure: {total_dbs}")
    # list top-level page titles
    for p in merged.get("pages", [])[:10]:
        print(" -", p.get("title"))
    if total_pages > 10:
        print(f" ... (+{total_pages-10} more)")


def list_children(block_id, page_size=100):
    r = req("GET", f"{ENDPOINT_BLOCKS}/{block_id}/children?page_size={page_size}")
    try:
        return r.json().get("results", [])
    except Exception:
        return []

TEXTUAL = {"paragraph","callout","toggle","bulleted_list_item","numbered_list_item","to_do","quote","heading_1","heading_2","heading_3"}

def block_plain_text(b):
    t = b.get("type")
    if t in TEXTUAL:
        rt = b[t].get("rich_text", [])
        return "".join([seg.get("plain_text","") for seg in rt])
    return ""

def has_block_marker_recursive(block_id, token, max_depth=2):
    # Search for `token` in this block's subtree (limited depth).
    stack = [(block_id, 0)]
    while stack:
        bid, depth = stack.pop()
        for child in list_children(bid):
            if token in block_plain_text(child):
                return True
            if depth < max_depth:
                t = child.get("type")
                if t == "column_list":
                    # Notion API doesn't return nested children directly; still push child id to traverse
                    stack.append((child["id"], depth+1))
                elif t in ("column","toggle","callout"):
                    stack.append((child["id"], depth+1))
    return False


def ensure_synced_library(state, library_page_title="Synced Library"):
    # Ensure a master page that holds original synced blocks exists; return page_id.
    pid = state["pages"].get(library_page_title)
    if pid:
        return pid
    payload = {
        "parent": {"type":"page_id","page_id": state.get("root_page_id") or state.get("root")},
        "icon": {"type":"emoji","emoji":"ðŸ”"},
        "properties": {"title":{"title":[{"type":"text","text":{"content":library_page_title}}]}},
    }
    r = req("POST",ENDPOINT_PAGES, data=json.dumps(payload))
    if expect_ok(r, "create synced library"):
        new_id = r.json().get("id")
        state["pages"][library_page_title]=new_id
        return new_id
    return None

def ensure_sync_original(state, lib_pid, sync_key, content=""):
    # Create (or find) an original synced_block tagged with SYNC_KEY::.
    children = list_children(lib_pid)
    for b in children:
        if b.get("type") == "synced_block" and b["synced_block"].get("synced_from") is None:
            inner = list_children(b["id"])
            for c in inner:
                if sync_key in (block_plain_text(c) or ""):
                    return b["id"]
    blocks = [{
        "object":"block","type":"synced_block",
        "synced_block":{"synced_from": None, "children":[
            {"object":"block","type":"callout","callout":{
                "icon":{"type":"emoji","emoji":"ðŸ”–"},
                "rich_text":[{"type":"text","text":{"content":f"{sync_key}"}},{"type":"text","text":{"content":"  â€¢  Do not edit this marker text"}}],
                "color":"gray_background"
            }},
            {"object":"block","type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content": content or "Synced original content"}}]}}
        ]}
    }]
    r = req("PATCH", f"{ENDPOINT_BLOCKS}/{lib_pid}/children", data=json.dumps({"children":blocks}))
    if expect_ok(r, "create sync original"):
        for res in r.json().get("results", []):
            if res.get("type") == "synced_block":
                return res.get("id")
    return None

def add_synced_reference_if_absent(target_page_id, original_block_id, sync_key):
    # Insert a synced reference to original into target, if marker absent.
    if has_block_marker_recursive(target_page_id, sync_key):
        return True
    block = {
        "object":"block","type":"synced_block",
        "synced_block":{"synced_from":{"block_id": original_block_id}}
    }
    r = req("PATCH", f"{ENDPOINT_BLOCKS}/{target_page_id}/children", data=json.dumps({"children":[block]}))
    return expect_ok(r, f"add sync ref {sync_key}")



def resolve_external_file(filename):
    base = os.getenv("ASSET_BASE_URL","").strip()
    if not base or not filename: 
        return None
    return url_join(base, filename)

def build_page_icon_cover(p):
    """Return (icon_dict_or_None, cover_dict_or_None) honoring emoji/icon/icon_file and cover/cover_file."""
    icon = None
    cover = None
    # Icon precedence: icon_file > icon_png > icon (emoji:... or url)
    if p.get("icon_file"):
        url = resolve_external_file(p.get("icon_file"))
        if url:
            icon = {"type":"external","external":{"url": url}}
    elif p.get("icon_png"):
        url = resolve_external_file(p.get("icon_png"))
        if url:
            icon = {"type":"external","external":{"url": url}}
    elif p.get("icon"):
        ic = p.get("icon")
        if isinstance(ic,str) and ic.startswith("emoji:"):
            icon = {"type":"emoji","emoji": ic.split(":",1)[1]}
        elif isinstance(ic,str) and (ic.startswith("http://") or ic.startswith("https://")):
            icon = {"type":"external","external":{"url": ic}}
    # Cover precedence: cover_file > cover_png > cover (url)
    if p.get("cover_file"):
        url = resolve_external_file(p.get("cover_file"))
        if url:
            cover = {"type":"external","external":{"url": url}}
    elif p.get("cover_png"):
        url = resolve_external_file(p.get("cover_png"))
        if url:
            cover = {"type":"external","external":{"url": url}}
    elif p.get("cover"):
        cv = p.get("cover")
        if isinstance(cv,str) and (cv.startswith("http://") or cv.startswith("https://")):
            cover = {"type":"external","external":{"url": cv}}
    return icon, cover


def make_marker(token):
    return {"object":"block","type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":token}}]}}

def has_exact_marker(block_id, token):
    for b in list_children(block_id):
        t = b.get("type")
        if t == "paragraph":
            rt = b[t].get("rich_text",[])
            if len(rt)==1 and (rt[0].get("type")=="text") and (rt[0].get("text",{}).get("content")==token):
                return True
    return False

    add_nav_links(state, merged.get('pages', []))

    add_mobile_tip(state, merged.get('pages', []))

    add_letter_legal_content(state, merged.get('pages', []))

    lib_id = ensure_synced_library(state)


def add_view_placeholders(state):
    """Add explicit helper blocks on hubs with deep links to databases as a best-effort stand-in for saved views creation."""
    hub_titles = ["Preparation Hub","Executor Hub","Family Hub"]
    items = [("Preparation Hub","Setup & Acceptance"), ("Executor Hub","Executor Tasks"), ("Family Hub","Letters")]
    for hub, db_title in items:
        pid = (state.get("pages") or {}).get(hub)
        dbid = (state.get("databases") or {}).get(db_title)
        if not pid or not dbid:
            continue
        token = f"VIEW_MARKER::{db_title}"
        if has_exact_marker(pid, token):
            continue
        children = [
            make_marker(token),
            {"object":"block","type":"callout","callout":{"icon":{"type":"emoji","emoji":"ðŸ“Š"},"color":"gray_background","rich_text":[{"type":"text","text":{"content":f"Embed a saved view of '{db_title}' here (manual step)."}}]}},
            {"object":"block","type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"Tip: Filter to Status = Active / Not Archived, then paste the view link and choose 'Create embed'."}}]}}
        ]
        req("PATCH", f"{ENDPOINT_BLOCKS}/{pid}/children", data=json.dumps({"children":children}))


def validate_yaml(merged):
    problems = []
    for p in merged.get("pages", []):
        if p.get("icon_file") and not os.getenv("ASSET_BASE_URL"):
            problems.append(f"Page '{p.get('title')}' has icon_file but ASSET_BASE_URL is not set.")
        if p.get("cover_file") and not os.getenv("ASSET_BASE_URL"):
            problems.append(f"Page '{p.get('title')}' has cover_file but ASSET_BASE_URL is not set.")
    if problems:
        print("YAML validation notes:")
        for msg in problems:
            print(" -", msg)


def link_to_page_block(page_id):
    return {"object":"block","type":"link_to_page","link_to_page":{"type":"page_id","page_id":page_id}}

def get_children(block_id, page_size=100):
    r = req("GET", f"{ENDPOINT_BLOCKS}/{block_id}/children?page_size={page_size}")
    return j(r).get("results", [])

def insert_children(block_id, children):
    r = req("PATCH", f"{ENDPOINT_BLOCKS}/{block_id}/children", data=json.dumps({"children":children}))
    return expect_ok(r, f"insert children into {block_id}")

def upsert_page(state, p, parent):
    """Minimal upsert: if title already exists in state, return its id; else create."""
    title = p.get("title")
    if not title:
        return None
    existing = (state.get("pages") or {}).get(title)
    if existing:
        return existing
    # fall back to create_page path
    return create_page(state, p, parent)


def validate_formula_complexity(schema, db_title):
    """Warn if formulas look overly complex (heuristic)."""
    if not isinstance(schema, dict):
        return []
    warnings = []
    for name, t in schema.items():
        if isinstance(t, dict) and t.get("type") == "formula":
            expr = t.get("expression") or t.get("formula") or ""
            depth = expr.count("prop(")
            if depth > 10 or len(expr) > 800:
                warnings.append(f"[{db_title}] Formula '{name}' may exceed Notion limits (props:{depth}, len:{len(expr)}).")
    return warnings


def find_page_id_by_title(state, title):
    """Find a page by title via Pages Index first; fall back to /search if enabled."""
    # index lookup
    pid = (state.get("pages") or {}).get(title)
    if pid:
        return pid
    if not os.getenv("ENABLE_SEARCH_FALLBACK", "1") == "1":
        return None
    payload = {"query": title, "filter": {"value": "page", "property":"object"}}
    r = req("POST",ENDPOINT_SEARCH, data=json.dumps(payload))
    data = j(r)
    results = [it for it in data.get("results",[]) if it.get("object")=="page"]
    if len(results)==1:
        return results[0].get("id")
    elif len(results)>1:
        print(f"[!] Ambiguous title search for '{title}': {len(results)} candidates.")
        return results[0].get("id")
    else:
        print(f"[!] No page found for '{title}' via search fallback.")
        return None


def validate_asset_host(sample_files):
    base = os.getenv("ASSET_BASE_URL","").strip()
    if not base or not sample_files:
        return
    import requests
    checked = 0
    for fn in sample_files:
        try:
            url = (base.rstrip("/") + "/" + fn.lstrip("/"))
            r = requests.head(url, timeout=7)
            if r.status_code >= 400:
                print(f"[!] Asset HEAD failed {r.status_code}: {url}")
            checked += 1
            if checked >= 3:
                break
        except Exception as e:
            print("[!] Asset HEAD exception:", e)
            break

ARTIFACT_DIR = os.getenv("ARTIFACT_DIR","artifacts")
os.makedirs(ARTIFACT_DIR, exist_ok=True)

def write_artifact(name, data):
    try:
        p = os.path.join(ARTIFACT_DIR, name)
        with open(p, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print("[!] Failed to write artifact", name, "â†’", e)

def capabilities_manifest():
    return {
        "automated": [
            "pages:create","pages:icons_covers","databases:create","databases:seed_rows",
            "relations:by_slug","formulas:create","synced_blocks:originals+refs",
            "helpers:nav_links","helpers:mobile_tips","letters:body+disclaimer",
            "artifacts:capabilities,preflight,ledger,transactions,relations"
        ],
        "manual_by_api": [
            "saved_views:create","linked_db_embeds:create","ui_rollups:configure_in_ui"
        ]
    }

def kebab(s):
    return re.sub(r'[^a-z0-9]+','-', (s or "").lower()).strip('-')

def collect_assets_from_pages(pages):
    files = []
    for p in pages:
        for key in ("icon_file","cover_file","icon_png","cover_png"):
            v = p.get(key)
            if isinstance(v,str) and not v.startswith("emoji:"):
                files.append(v)
        for c in (p.get("children") or []):
            files.extend(collect_assets_from_pages([c]))
    return files

def preflight(M):
    report = {"errors":[], "warnings":[], "counts":{}}
    # slugs
    seen = set()
    for p in M.get("pages",[]):
        title = p.get("title")
        slug = p.get("slug") or kebab(title)
        p["slug"] = slug
        if slug in seen:
            report["errors"].append(f"Duplicate slug: {slug} for page '{title}'")
        seen.add(slug)
    # assets
    assets = collect_assets_from_pages(M.get("pages",[]))
    report["counts"]["asset_candidates"] = len(assets)
    base = os.getenv("ASSET_BASE_URL","").strip()
    import requests
    for fn in assets:
        url = fn if fn.startswith("http") else (base.rstrip("/") + "/" + fn.lstrip("/")) if base else None
        if not url:
            report["warnings"].append("ASSET_BASE_URL not set; external icons/covers may not render.")
            break
        try:
            r = requests.head(url, timeout=7)
            if r.status_code >= 400:
                report["warnings"].append(f"Asset unreachable ({r.status_code}): {url}")
        except Exception as e:
            report["warnings"].append(f"Asset check error for {url}: {e}")
    # placeholder scan
    tokens = ["[insert", "<insert", "{insert", "[INSERT", "lorem ipsum"]
    def _walk(p):
        texts = []
        for key in ("Body","Disclaimer","description"):
            v = p.get(key)
            if isinstance(v,str): texts.append(v)
        for c in (p.get("children") or []):
            texts.extend(_walk(c))
        return texts
    all_texts = []
    for p in M.get("pages",[]): all_texts.extend(_walk(p))
    for t in all_texts:
        lt = t.lower()
        if any(tok in lt for tok in tokens):
            report["errors"].append("Placeholder text detected in content blocks; remove before deploy.")
            break
    write_artifact("preflight_report.json", report)
    return report

def ensure_ledger_db(state, parent_id=None):
    title = "Admin â€“ Deployment Ledger"
    if (state.get("databases") or {}).get(title):
        return state["databases"][title]
    pid = parent_id or state.get("pages",{}).get("Admin â€“ Rollout") or state.get("root_page_id") or state.get("root")
    schema = {
        "Feature Key": {"title": {}},
        "Page ID": {"rich_text": {}},
        "Block ID": {"rich_text": {}},
        "Version": {"rich_text": {}},
        "Status": {"select": {"options":[{"name":"added"},{"name":"missing"},{"name":"reconciled"}]}},
    }
    payload = {"parent":{"type":"page_id","page_id":pid},"title":[{"type":"text","text":{"content":title}}],"properties":schema}
    r = req("POST",ENDPOINT_DATABASES, data=json.dumps(payload))
    if expect_ok(r, "create ledger db"):
        did = j(r).get("id")
        state.setdefault("databases",{})[title]=did
        return did
    return None

def ledger_add(state, feature_key, page_id, block_id, status="added"):
    entry = {"feature_key":feature_key,"page_id":page_id,"block_id":block_id,"status":status,"ts":datetime.datetime.utcnow().isoformat()+"Z"}
    try:
        p = os.path.join(ARTIFACT_DIR,"deployment_ledger.json")
        cur = []
        if os.path.exists(p):
            with open(p,"r",encoding="utf-8") as f: cur = json.load(f)
        cur.append(entry)
        with open(p,"w",encoding="utf-8") as f: json.dump(cur,f,indent=2,ensure_ascii=False)
    except Exception as e:
        print("[!] ledger json write failed:", e)
    did = (state.get("databases") or {}).get("Admin â€“ Deployment Ledger") or ensure_ledger_db(state)
    if did:
        props = {
            "Feature Key":{"title":[{"type":"text","text":{"content":feature_key}}]},
            "Page ID":{"rich_text":[{"type":"text","text":{"content":page_id or ""}}]},
            "Block ID":{"rich_text":[{"type":"text","text":{"content":block_id or ""}}]},
            "Version":{"rich_text":[{"type":"text","text":{"content":os.getenv("BUILD_VERSION","v3.8.2")}}]},
            "Status":{"select":{"name":status}},
        }
        req("POST",ENDPOINT_PAGES, data=json.dumps({"parent":{"database_id":did},"properties":props}))

TXN = {"created_pages": [], "created_dbs": []}

def txn_log_page(pid):
    TXN["created_pages"].append(pid)

def txn_log_db(did):
    TXN["created_dbs"].append(did)

def rollback():
    print("[!] Rolling back this run...")
    for pid in reversed(TXN["created_pages"]):
        try:
            req("PATCH", f"{ENDPOINT_PAGES}/{pid}", data=json.dumps({"archived": True}))
        except Exception as e:
            print("[!] Failed to archive page", pid, e)
    for did in reversed(TXN["created_dbs"]):
        try:
            req("PATCH", f"{ENDPOINT_DATABASES}/{did}", data=json.dumps({"archived": True}))
        except Exception:
            pass
    write_artifact("transaction_log.json", TXN)

def finalize_artifacts(state):
    write_artifact("capabilities.json", capabilities_manifest())
    write_artifact("relations_report.json", state.get("relations_report") or [])


### MAIN_ORCHESTRATION_V382 ###
def main():
    """Main deployment orchestration with comprehensive error handling."""
    try:
        # Environment setup
        os.environ.setdefault("BUILD_VERSION","v3.8.2")
        
        # Validate environment variables
        if not os.getenv(ENV_NOTION_TOKEN):
            raise ValueError(f"Missing required environment variable: {ENV_NOTION_TOKEN}")
        if not os.getenv("NOTION_PARENT_PAGEID"):
            raise ValueError("Missing required environment variable: NOTION_PARENT_PAGEID")
        
        # Load configuration
        print("[*] Loading YAML configuration...")
        try:
            merged = load_all_yaml(args.dir)
        except FileNotFoundError as e:
            print(f"[!] Configuration files not found: {e}")
            return 1
        except yaml.YAMLError as e:
            print(f"[!] Invalid YAML configuration: {e}")
            return 1
        
        # Preflight checks
        print("[*] Running preflight checks...")
        pf = preflight(merged)
        write_artifact("preflight_report.json", pf)
        if pf.get("errors"):
            print("[!] Preflight failed. See artifacts/preflight_report.json")
            for error in pf.get("errors", []):
                print(f"    - {error}")
            return 1
        
        # Write capabilities manifest
        write_artifact("capabilities.json", capabilities_manifest())
        
        # Main deployment
        state = None
        try:
            print("[*] Initializing deployment state...")
            state = init_state()
            
            print("[*] Creating root structure...")
            ensure_root(state, merged)
            
            print("[*] Creating pages...")
            create_all_pages(state, merged.get("pages", []))
            
            print("[*] Creating databases...")
            create_all_databases(state, merged.get("db", {}).get("schemas", {}))
            
            print("[*] Seeding databases...")
            seed_all_databases(state, merged.get("db", {}).get("seed_rows", {}))
            
            # CSV Import Feature
            if os.getenv("ENABLE_CSV_IMPORT", "true").lower() == "true":
                print("[*] Importing CSV data...")
                csv_results = import_csv_data(state)
                if csv_results["stats"]["imported"] > 0:
                    print(f"    Imported {csv_results['stats']['imported']} CSV rows")
            
            # Mobile Optimization Feature
            if os.getenv("ENABLE_MOBILE_OPTIMIZATION", "true").lower() == "true":
                print("[*] Optimizing for mobile...")
                mobile_results = optimize_for_mobile(state)
                if mobile_results["optimized_hubs"]:
                    print(f"    Optimized {len(mobile_results['optimized_hubs'])} hubs for mobile")
                if mobile_results["dashboard_created"]:
                    print("    Created mobile dashboard")
            
            # Synced Rollups Feature
            if os.getenv("ENABLE_SYNCED_ROLLUPS", "true").lower() == "true":
                print("[*] Setting up cross-database synced rollups...")
                rollup_results = setup_synced_rollups(state)
                print(f"    Synced {rollup_results['synced']} rollups across databases")
                if rollup_results['cached'] > 0:
                    print(f"    Used cache for {rollup_results['cached']} rollups")
            
            print("[*] Setting up synced library...")
            lib_id = ensure_synced_library(state)
            
            print("[*] Adding navigation links...")
            add_nav_links(state, merged.get('pages', []))
            
            print("[*] Adding mobile tips...")
            add_mobile_tip(state, merged.get('pages', []))
            
            print("[*] Adding letter/legal content...")
            add_letter_legal_content(state, merged.get('pages', []))
            
            print("[*] Seeding view blueprints...")
            seed_view_blueprints(state, merged)
            
            print("[*] Seeding rollup blueprints...")
            seed_rollup_blueprints(state, merged)
            
            print("[*] Adding hub blueprint callouts...")
            add_hub_blueprint_callouts(state)
            
            print("[*] Updating rollout summary...")
            update_rollout_summary(state)
            
            # Role-Based Permissions Feature
            if os.getenv("ENABLE_PERMISSIONS", "true").lower() == "true":
                print("[*] Setting up role-based permissions...")
                perm_results = setup_role_permissions(state)
                if perm_results.get("updated_pages", 0) > 0:
                    print(f"    Applied permissions to {perm_results['updated_pages']} pages")
                if perm_results.get("updated_databases", 0) > 0:
                    print(f"    Applied permissions to {perm_results['updated_databases']} databases")
            
            # Data Validation Framework Feature
            if os.getenv("ENABLE_DATA_VALIDATION", "true").lower() == "true":
                print("[*] Setting up data validation framework...")
                validation_results = setup_data_validation(state)
                print(f"    Defined validation rules for {validation_results['entity_types']} entity types")
                if validation_results.get('custom_validators', 0) > 0:
                    print(f"    Registered {validation_results['custom_validators']} custom validators")
            
            # Relation Integrity Enforcement Feature
            if os.getenv("ENABLE_RELATION_INTEGRITY", "true").lower() == "true":
                print("[*] Setting up relation integrity enforcement...")
                integrity_results = setup_relation_integrity(state)
                print(f"    Defined {integrity_results['relations_defined']} relations")
                if integrity_results.get('orphans_detected', 0) > 0:
                    print(f"    Detected {integrity_results['orphans_detected']} orphaned records")
                if integrity_results.get('circular_references', 0) > 0:
                    print(f"    WARNING: Found {integrity_results['circular_references']} circular reference chains")
            
            # Batch Operations Support Feature
            if os.getenv("ENABLE_BATCH_OPERATIONS", "true").lower() == "true":
                print("[*] Setting up batch operations support...")
                batch_results = setup_batch_operations(state)
                print(f"    Configured batch size: {batch_results['batch_size']}, max workers: {batch_results['max_workers']}")
                if batch_results.get('completed', 0) > 0:
                    print(f"    Completed {batch_results['completed']} batch operations")
                if batch_results.get('failed', 0) > 0:
                    print(f"    WARNING: {batch_results['failed']} operations failed")
            
            # Formula Auto-Sync Feature
            if os.getenv("ENABLE_FORMULA_SYNC", "true").lower() == "true":
                print("[*] Setting up formula auto-sync...")
                formula_results = setup_formula_sync(state)
                print(f"    Registered {formula_results['formulas_registered']} formulas")
                if formula_results.get('formulas_synced', 0) > 0:
                    print(f"    Synced {formula_results['formulas_synced']} formulas")
                if formula_results.get('validation_errors', 0) > 0:
                    print(f"    WARNING: {formula_results['validation_errors']} validation errors")
            
            # Conditional Page Creation Feature
            if os.getenv("ENABLE_CONDITIONAL_PAGES", "true").lower() == "true":
                print("[*] Setting up conditional page creation...")
                conditional_results = setup_conditional_pages(state)
                print(f"    Defined {conditional_results['rules_defined']} conditional rules")
                if conditional_results.get('pages_created', 0) > 0:
                    print(f"    Created {conditional_results['pages_created']} conditional pages")
                if conditional_results.get('pages_skipped', 0) > 0:
                    print(f"    Skipped {conditional_results['pages_skipped']} pages (conditions not met)")
                if conditional_results.get('errors', 0) > 0:
                    print(f"    WARNING: {conditional_results['errors']} errors during creation")
            
            # Progress Tracking Dashboard Feature
            if os.getenv("ENABLE_PROGRESS_DASHBOARD", "true").lower() == "true":
                print("[*] Setting up progress tracking dashboard...")
                progress_results = setup_progress_dashboard(state)
                print(f"    Created {progress_results['dashboards_created']} progress dashboards")
                if progress_results.get('metrics_tracked', 0) > 0:
                    print(f"    Tracking {progress_results['metrics_tracked']} progress metrics")
                if progress_results.get('visualizations', 0) > 0:
                    print(f"    Generated {progress_results['visualizations']} progress visualizations")
            
            # Friends to Contact Page Feature
            if os.getenv("ENABLE_FRIENDS_CONTACT", "true").lower() == "true":
                print("[*] Setting up friends to contact page...")
                contact_results = setup_friends_contact_page(state)
                print(f"    Organized {contact_results['contacts_organized']} contacts")
                if contact_results.get('categories_created', 0) > 0:
                    print(f"    Created {contact_results['categories_created']} contact categories")
                if contact_results.get('templates_created', 0) > 0:
                    print(f"    Generated {contact_results['templates_created']} communication templates")
                if contact_results.get('notifications_configured', 0) > 0:
                    print(f"    Configured {contact_results['notifications_configured']} notification rules")
            
            print("[*] Finalizing artifacts...")
            finalize_artifacts(state)
            
            print("[OK] Deployment completed successfully.")
            return 0
            
        except requests.exceptions.RequestException as e:
            print(f"[!] Notion API error: {e}")
            if state:
                print("[*] Attempting rollback...")
                rollback()
            return 1
            
        except KeyError as e:
            print(f"[!] Missing required configuration key: {e}")
            if state:
                print("[*] Attempting rollback...")
                rollback()
            return 1
            
        except Exception as e:
            print(f"[!] Unexpected deployment error: {e}")
            if state:
                print("[*] Attempting rollback...")
                rollback()
            raise
            
    except KeyboardInterrupt:
        print("\n[!] Deployment interrupted by user")
        return 130  # Standard exit code for SIGINT
        
    except Exception as e:
        print(f"[!] Fatal error: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    args = parse_args()
    sys.exit(main() or 0)
